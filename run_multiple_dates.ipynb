{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56bdf8e-b22f-4fd2-905a-87d057d9647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import scipy.sparse as sps\n",
    "import pickle\n",
    "import time \n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('./source')\n",
    "import utils\n",
    "import kernel\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5094aa1-15b0-4260-a734-aeef637f88fe",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586a8880-b17d-47c0-8650-216a3c9525ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ver = 1\n",
    "use_maturity_mask= True \n",
    "flg_mp =False \n",
    "num_t_each_trunk =1000 \n",
    "\n",
    "freq = 'daily'\n",
    "R = 10 \n",
    "l_fixed = 10.0 \n",
    "alpha = 0.05 \n",
    "delta = 0.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd9934-2927-4e55-9a14-f2ec9c3927d9",
   "metadata": {},
   "source": [
    "# Load data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4df5266-5c5c-4c13-9676-20278be44a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ./Data/B_max_ttm_10yr/\n"
     ]
    }
   ],
   "source": [
    "lst_R_fit=None\n",
    "\n",
    "### where to save output\n",
    "dir_out = './KR_ret_example/'\n",
    "if not os.path.isdir(dir_out):\n",
    "    os.makedirs(dir_out)\n",
    "print('*'*3 +'Save results to: '+ '*'*3+'\\n'+dir_out)\n",
    "\n",
    "### get path and load lookup table\n",
    "dir_B = './Data/B_max_ttm_10yr/'\n",
    "print('Reading data from {}'.format(dir_B))\n",
    "df_t_lookup_freq = pd.read_pickle(dir_B + 'df_t_lookup_{}.pkl'.format(freq))\n",
    "df_t_lookup_daily = pd.read_pickle(dir_B + 'df_t_lookup_{}.pkl'.format('daily'))\n",
    "\n",
    "B_mat = np.load(dir_B + 'B_mat.npy')\n",
    "Bc_shift_mat = np.load(dir_B + 'Bc_shift_mat.npy')\n",
    "with open(dir_B + \"dict_par.pkl\", \"rb\") as handle:\n",
    "    dict_par = pickle.load(handle)\n",
    "nmax, Nmax, prefix_C, dir_npz = [dict_par[key] for key in ['nmax','Nmax','prefix_C','npz_dir']]\n",
    "# update dir_npz\n",
    "# dir_npz='./Data/npz_C_10yr_ver_12312021/'\n",
    "\n",
    "\n",
    "# load daily risk-free rate\n",
    "df_rf = pd.read_pickle('./data_supplement/df_riskfree_daily_all.pkl').KR_LS\n",
    "\n",
    "# load mask\n",
    "dir_mask = './mask/'\n",
    "mat_mask_maturity = np.load(dir_mask + 'mat_filter_maturity_90days.npy')\n",
    "mat_nt = np.load(dir_mask + 'mat_nt.npy')\n",
    "mat_ytm = np.load(dir_mask + 'mat_ytm.npy')\n",
    "\n",
    "# load daily discount curve\n",
    "df_g_daily = pd.read_pickle('./data_supplement/df_kr_g.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1482da-8da8-4935-b765-39f9202454af",
   "metadata": {},
   "source": [
    "# Generate the kernel matrix for fixed $\\alpha$ and $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f4847-a774-4019-90ee-7f9419283bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = kernel.generate_kernel_matrix(alpha, delta, Nmax, Nmax)\n",
    "\n",
    "# SVD\n",
    "U,D_diag,Vh = np.linalg.svd(K)\n",
    "V = Vh.T\n",
    "D = np.diag(D_diag) # D is a matrix\n",
    "DV_inv = V@np.diag(1/np.sqrt(D_diag))\n",
    "assert np.isclose(U[:,:10],V[:,:10]).all()\n",
    "\n",
    "dict_svd = {'V':V,\n",
    "            'D_diag':D_diag,\n",
    "            'DV_inv':DV_inv}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4577c-cb32-49da-95da-be61cd3a4484",
   "metadata": {},
   "source": [
    "# Fit KR model for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfce4818-ca61-4f69-9bf6-fcf1e5659574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:2834, t_freq:2834, date:1972-10-24, nt: 52, date_s:1\n"
     ]
    }
   ],
   "source": [
    "lst_t_freq = [2834]\n",
    "\n",
    "for t_freq in lst_t_freq:\n",
    "    t = df_t_lookup_freq.iloc[t_freq].t\n",
    "    today = df_t_lookup_freq.index[t_freq]\n",
    "    today_str = today.strftime('%Y-%m-%d')\n",
    "\n",
    "    # return over x days. find the subsequent date\n",
    "    if t+1==len(df_t_lookup_daily) or np.count_nonzero(B_mat[:,t])==0: \n",
    "        # can't find the subsequent date or no eligible securities today\n",
    "        print('skipping t:{}, t_freq:{}, date:{}'.format(t,t_freq,today_str))\n",
    "        continue\n",
    "\n",
    "    date_s = (df_t_lookup_daily.index[t+1]-df_t_lookup_daily.index[t]).days\n",
    "    B = B_mat[:,t]\n",
    "    nt = int(mat_nt[t])\n",
    "\n",
    "    # filter step\n",
    "    if use_maturity_mask:\n",
    "        mask_keep = mat_mask_maturity[t,:nt]\n",
    "        mask_keep = np.logical_and(mask_keep, mat_ytm[t,:nt] < 0.25) \n",
    "    else:\n",
    "        mask_keep = np.full(nt, True)\n",
    "\n",
    "    csr_mat_name = dir_npz+prefix_C+'C_'+str(t)+'.npz'\n",
    "    csr_mat = sps.load_npz(csr_mat_name)\n",
    "\n",
    "    # remove empty rows from B and C\n",
    "    # apply filter\n",
    "    B = B[:nt][mask_keep]\n",
    "    Bc_shift = Bc_shift_mat[:nt,t][mask_keep]\n",
    "    C = csr_mat.toarray()[:nt,1:][mask_keep]\n",
    "    nt = len(B)\n",
    "\n",
    "    print('t:{}, t_freq:{}, date:{}, nt: {}, date_s:{}'.format(t,t_freq,today_str, nt, date_s))\n",
    "\n",
    "    # normalize prices to 1\n",
    "    Bc_shift = (1/B)*Bc_shift\n",
    "    C = (1/B)[:,np.newaxis]*C\n",
    "    B = np.ones(nt)*1\n",
    "\n",
    "    ### the next cash flow should be on t+date_s. No cashflow in between by construction\n",
    "    # assert C[:,:date_s-1].sum()==0\n",
    "\n",
    "    # get return of securities\n",
    "    rf = (1+df_rf.loc[today])**date_s-1 # scalar\n",
    "    ret = (Bc_shift-B)/B\n",
    "    rx = ret-rf\n",
    "\n",
    "    # get one-day excess return of zcb\n",
    "    g = df_g_daily.iloc[t].values\n",
    "    # g_shift=df_g_daily.iloc[t+1].values\n",
    "    # g_shift_2=np.roll(g_shift,date_s)\n",
    "    # g_shift_2[:date_s]=1\n",
    "    # rx_g=(g_shift_2-g)/g-rf # the first (date_s-1) values are artificial and should be discarded\n",
    "\n",
    "    #C_tilde=C@np.diag(g[:Nmax])\n",
    "\n",
    "    Z_bar = C[:,date_s-1:]@np.diag(g[date_s-1:Nmax]) # dim: (nt, Nmax-date_s+1)\n",
    "    Z = Z_bar[:,1:] # dim: (nt, Nmax-date_s)\n",
    "\n",
    "    dict_full = models.one_fit(Z = Z,\n",
    "                l_unscaled = l_fixed,\n",
    "                rx = rx, # (Bc_shift-B)/B - rf\n",
    "                date_s = date_s, # number of day shifts\n",
    "                K = K # 2D, specific to alpha\n",
    "                )\n",
    "\n",
    "    # factor model\n",
    "    dict_fm = models.FM_ridge_solution(Z = Z,\n",
    "                l_unscaled = l_fixed,\n",
    "                rx = rx, # (Bc_shift-B)/B - rf\n",
    "                date_s = date_s, # number of day shifts\n",
    "                V = dict_svd['V'], # svd of K\n",
    "                D_diag = dict_svd['D_diag'], # svd of K\n",
    "                R = R, # max number of factors\n",
    "                lst_R_fit = lst_R_fit # list of r used for fitting. will override R above\n",
    "                )\n",
    "     with open(dir_out+'dict_ret_curve_tfreq_{}_t_{}.pkl'.format(t_freq,t),'wb') as handle:\n",
    "            pickle.dump(dict_out,handle,protocol=pickle.HIGHEST_PROTOCOL)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd761b56-8d11-4c8c-9b96-3e23553e4983",
   "metadata": {},
   "source": [
    "# Compile results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b4191-5f9e-4253-9279-de7f48ef9c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
